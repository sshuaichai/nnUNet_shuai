# nnUNet是一个用于医学图像分割的深度学习框架.---训练最佳的分割模型！！！

nnUNet旨在通过自动化配置过程来简化医学图像分割任务的复杂性，使研究人员和开发人员能够更容易地应用深度学习模型于各种医学成像数据。

nnUNet的核心特点和用途包括：
1.自动化的预处理和后处理：nnUNet自动处理数据的归一化、重采样等预处理步骤，以及分割后的结果处理，如去除小连通区域等。
2.灵活的网络架构适配：根据输入数据的特点（如维度、大小等），nnUNet能够自动选择和调整最合适的网络架构，包括2D、3D全分辨率、3D低分辨率等。
3.自动化的超参数选择：nnUNet能够根据数据集自动选择最优的训练超参数，如学习率、批量大小等。
4.跨数据集泛化能力：nnUNet在多个医学图像分割挑战赛中取得了优异的成绩，显示了其良好的泛化能力。
5.易用性：nnUNet提供了一系列命令行工具，使得从数据准备到模型训练和评估的整个流程变得简单易行。

nnUNet的主要用途是医学图像分割，包括但不限于：
器官和组织的分割：如肝脏、肺部、心脏、肿瘤等在CT、MRI图像中的精确分割。
病变检测：自动识别和分割图像中的病变区域，如肿瘤、炎症等。
辅助诊断：通过精确的图像分割辅助医生进行疾病诊断和治疗规划。
医学研究：在生物医学研究中，用于分析和量化医学图像数据。
总之，nnUNet是一个功能强大、使用方便的医学图像分割工具，通过自动化的流程和优化的网络架构，为医学图像分析提供了有效的解决方案。

------------------------------------------------------------
# documentation：使用目录
# 一键训练指令（已完成）

nnUNetv2_plan_and_preprocess -d 521 --verify_dataset_integrity

nnUNetv2_train 521 3d_fullres 0  
nnUNetv2_train 521 3d_fullres 1  
nnUNetv2_train 521 3d_fullres 2  
nnUNetv2_train 521 3d_fullres 3 
nnUNetv2_train 521 3d_fullres 4  

nnUNetv2_train 521 3d_fullres 0 --val --npz  
nnUNetv2_train 521 3d_fullres 1 --val --npz  
nnUNetv2_train 521 3d_fullres 2 --val --npz  
nnUNetv2_train 521 3d_fullres 3 --val --npz  
nnUNetv2_train 521 3d_fullres 4 --val --npz

nnUNetv2_find_best_configuration 521 -c 3d_fullres

==========================推理前，先查看推理指令，最后生成[predictions]（创建）、和[postprocessed_predictions]文件（创建）

nnUNetv2_predict -d Dataset521_Heart -i D:\zhuomian\nnUNet_desk_v2\nnUNet_raw\Dataset521_Heart\imagesTs -o D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\predictions -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetPlans

nnUNetv2_apply_postprocessing -i D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\predictions -o D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\postprocessed_predictions -pp_pkl_file D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\postprocessing.pkl -np 8 -plans_json D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\plans.json
尝试一下只保存模型最佳检查点，然后进行推理（成功了以后就可以为所欲为..）

---------------------------------------------------------------
# 如何在新数据集上运行 nnU-Net
给定一些数据集，nnU-Net 完全自动配置与其属性匹配的整个分割管道。 nnU-Net 涵盖了整个流程，从预处理到模型配置、模型训练、后处理一直到集成。
运行 nnU-Net 后，训练好的模型可以应用于测试用例进行推理。

------------------------------------------------------------------
`炼丹顺序`:
#首先，加载环境
```1.conda and python
cd "C:\Users\13639\.conda\envs\nnUNet_v2"
```
```2.用作标准化基线、开箱即用的分割算法或使用预训练模型运行 推理：
pip install nnunetv2
"C:\Users\13639\.conda\envs\nnUNet_v2\Lib\site-packages\nnunetv2"
```
```3.指定環境變量
windows系统
set nnUNet_raw = nnUNet-master/nnunetv2/nnUNet_raw
set nnUNet_preprocessed = nnUNet-master/nnunetv2/nnUNet_preprocessed
set nnUNet_results = nnUNet-master/nnunetv2/nnUNet_results
```
炼丹炉：
```
Linux系统
export nnUNet_raw='/root/autodl-tmp/nnUNet_raw'
export nnUNet_preprocessed='/root/autodl-tmp/nnUNet_preprocessed'
export nnUNet_results='/root/autodl-tmp/nnUNet_results'

```
``` mv linux移动文件到指定目录 
cd /root
unzip autodl-tmp/nnUNet_preprocessed.zip -d autodl-tmp
unzip autodl-tmp/Dataset507_Lung.zip -d autodl-tmp

mv Dataset507_Lung miniconda3/lib/python3.10/site-packages/nnunetv2/nnUNet_raw
```
```4.安裝網絡拓撲圖
pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git
```
安装完毕
---------------------------------------------------

```angular2html
## 本地：
安装的地址在 "C:\Users\13639\.conda\envs\nnUNet_v2\Lib\site-packages\nnunetv2" (調參)
环境地址在： "C:\Users\13639\.conda\envs\nnUNet_v2"（不需要）
直接運行：
煉丹爐：
`root`中运行即可
或者
(base) C:\Users\13639>conda activate nnunet_v2
(nnunet_v2) C:\Users\13639>运行命令
 `拒絕訪問時則以管理員身份命令運行！`
```
![img.png](img.png)

# 1.数据集格式
nnU-Net 期望数据集采用结构化格式。这种格式的灵感来自于Medical Segmentation Decthlon的数据结构。请阅读 本文，了解如何设置与 nnU-Net 兼容的数据集的信息。
### 从版本 2 开始，我们支持多种图像文件格式（.nii.gz、.png、.tif、...）！阅读 dataset_format 文档以了解更多信息！

`nnU-Net v1 `的数据集可以通过运行转换为 `V2 nnUNetv2_convert_old_nnUNet_dataset INPUT_FOLDER  OUTPUT_DATASET_NAME`。
请记住，v2 调用数据集 `DatasetXXX_Name`（而不是任务），
其中 `XXX` 是 3 位数字。请提供旧任务的路径，而不仅仅是任务名称。 nnU-Net V2 不知道 v1 任务在哪里！

# 炼丹前准备: 本地生成json文件、转换数据集id：  （只要在相同的環境中，代碼py在當地點開始也可以，但是終端必須在envs的代碼中運行！）
1.1 生成json文件: 在本地代码[generate_dataset_json_Example.py]以脾脏示例 / 环境中使用命令行（需修改特定名称）
    确保目标文件夹有以下结构： （需要自己手动生成想要的dataset.json、_0000模态、..）
nnUNet_raw/Dataset002_Heart （格式：DatasetXXX_YYY=Dataset002_心脏 =Dataset（3位）标识符_（唯一）数据集名称)/）
├── dataset.json
├── imagesTr（必须）
│   ├── la_003_0000.nii.gz
│   ├── la_004_0000.nii.gz
│   ├── ...
├── imagesTs（可选）
│   ├── la_001_0000.nii.gz
│   ├── la_002_0000.nii.gz
│   ├── ...
└── labelsTr（必须）
    ├── la_003.nii.gz
    ├── la_004.nii.gz
    ├── ...


1.2 `convert_MSD_dataset` :"文件地址" 到 `nnUNet——raw`
[convert_MSD_dataset.py]会加载并更新旧版的dataset.json文件。可以直接用于2.预处理


## 2.实验计划和预处理
给定一个新数据集，nnU-Net 将`提取数据集指纹（一组特定于数据集的属性，例如图像大小、体素间距、强度信息等）`。
此信息用于`设计三种 U-Net 配置`。每个管道都在其自己的数据集预处理版本上运行。
###### 运行`指纹提取、实验规划和预处理`的最简单方法是使用：`nnUNetv2_plan_and_preprocess -d DATASET_ID --verify_dataset_integrity`
地址："D:\zhuomian\nnUNet-master\nnunetv2\experiment_planning\verify_dataset_integrity.py"验证标签是否符合预期
```angular2html
nnUNetv2_plan_and_preprocess -d 521 --verify_dataset_integrity
或者多个同时
nnUNetv2_plan_and_preprocess -d 11 12 13 ... --verify_dataset_integrity
```
`DATASET_ID = 11`
我们建议--verify_dataset_integrity您在第一次运行此命令时执行此操作。这将检查一些最常见的错误源！

您还可以通过给出 来`一次处理多个`数据集`-d 1 2 3 [...]`。如果您已经知道`需要什么 U-Net 配置`，您也可以使用 指定`-c 3d_fullres`
（请确保在这种情况下调整 -np！）。有关所有可用选项的更多信息，请运行`nnUNetv2_plan_and_preprocess -h`。
```
nnUNetv2_plan_and_preprocess -d 11 -c 3d_fullres --verify_dataset_integrity
```

### `nnUNetv2_plan_and_preprocess` 将在 `nnUNet_preprocessed `文件夹中创建一个以`数据集`命名的新子文件夹。命令完成后， 将出现一个
` dataset_fingerprint.json`文件以及一个`nnUNetPlans.json `文件供您查看（如果您感兴趣的话！）。 还有一些子文件夹包含 UNet 配置的预处理数据。
[可选] 如果您希望将事物分开，您还可以使用
`nnUNetv2_extract_fingerprint`  指纹提取
`nnUNetv2_plan_experiment` 实验规划
`nnUNetv2_preprocess` 预处理
（按顺序）。


# 3.模型训练
### 概述
您可以选择应该训练哪些配置（2d、3d_fullres、3d_lowres、3d_cascade_fullres）！
如果您不知道什么对您的数据表现最好，只需运行所有这些，然后让 nnU-Net 找出最好的一个。由你决定！

nnU-Net 在训练案例上通过 5 倍交叉验证来训练所有配置。 1）这是所必需的，以便 nnU-Net 可以估计每种配置的性能， 并告诉您应该使用哪一种配置来解决分割问题，
2）一种获得良好模型集成的自然方法（对这 5 个模型的输出进行平均）预测）以提高性能。

您可以影响 nnU-Net 用于 5 折交叉验证的分割（请参见`如何在 nnU-Net 中生成自定义分割`）。 如果您希望在所有训练案例上训练单个模型，这也是可能的（见下文）。

### 请注意，并非所有 U-Net 配置都是为所有数据集创建的。在`图像尺寸较小`的数据集中，U-Net 级联（以及 3d_lowres 配置）被省略，
   因为`全分辨率 U-Net `的 patch 大小`已经覆盖了`输入图像的很大一部分。

# 3.3 使用多个 GPU 进行训练
如果您可以使用多个 GPU，那么使用它们的最佳方法是一次训练多个 nnU-Net，每个 GPU 上一个。这是因为数据并行性永远不会完美地线性扩展，
尤其是对于小型网络（例如 nnU-Net 使用的网络）。
例子：
```angular2html
CUDA_VISIBLE_DEVICES=0 nnUNetv2_train DATASET_NAME_OR_ID 2d 0 [--npz] & # train on GPU 0 ,2d 0折
CUDA_VISIBLE_DEVICES=1 nnUNetv2_train DATASET_NAME_OR_ID 2d 1 [--npz] & # train on GPU 1

Windows: 不设置好像也行，也是cuda ： 0
1.set CUDA_VISIBLE_DEVICES=0
2.nnUNetv2_train 521 3d_fullres 1
3.显示：Using device: cuda:0
...
wait...
```
## 重要提示：出于速度原因，第一次运行训练时，nnU-Net 会将`预处理数据`提取到未压缩的 numpy 数组中！
## 此操作必须在开始多次相同配置的训练之前完成！ 等待开始后续折叠，直到第一次训练使用 GPU！ 根据数据集大小和您的系统，这最多只需要几分钟。

如果您坚持运行 DDP 多 GPU 训练，我们可以满足您的需求：
```
nnUNetv2_train 11 2d 0 [--npz] -num_gpus X
```
再次请注意，这比在单独的 GPU 上运行单独的训练要慢。仅当您手动干扰 nnU-Net 配置并且正在使用更大的 patch 和/或批量大小训练更大的模型时，DDP 才有意义！
使用时重要`-num_gpus`：
1.如果您使用 2 个 GPU 进行训练，但系统中有更多 GPU，则需要通过 ```CUDA_VISIBLE_DEVICES=0,1```（或任何您的 id）指定应使用哪些 GPU。
2.您指定的 GPU 数量`不能多于`小批量中的样本数量。如果批量大小为` 2`，则最多 `2` 个 GPU！
3.确保您的批量大小可以被您使用的 GPU 数量`整除`，否则您将无法充分利用您的硬件。
与旧的 nnU-Net 相比，DDP 现在完全没有麻烦。享受！

## 3.1 训练模型是通过`nnUNetv2_train`命令完成的。命令的一般结构是：
`nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD [additional options, see -h]`
修改训练参数，请见：
C:\Users\13639\AppData\Local\Programs\Python\Python311\Lib\site-packages\nnunetv2\training\nnUNetTrainer\nnUNetTrainer.py
```angular2html
nnUNetv2_train 11 2d 0 1 2 3 4
nnUNetv2_train: error: unrecognized arguments: 1 2 3 4 连着不行

nnUNetv2_train 521 2d 0
nnUNetv2_train 521 2d 1

重新下载后：
nnUNetv2_train 521 3d_fullres 0  
nnUNetv2_train 521 3d_fullres 1  
nnUNetv2_train 521 3d_fullres 2  
nnUNetv2_train 521 3d_fullres 3 
nnUNetv2_train 521 3d_fullres 4  
训练全部5折后 

里面含有[validation]（训练集中的一部分）、[checkpoint_best.pth]、[checkpoint_final.pth]、[progress.png]...

debug.json：包含用于训练该模型的蓝图和推断参数的摘要以及一堆其他内容。不容易阅读，但对于调试非常有用;-)
checkpoint_best.pth：训练期间识别的最佳模型的检查点文件。现在不使用，除非你明确告诉 nnU-Net 使用它。
checkpoint_final.pth：最终模型的检查点文件（训练结束后）。这是用于验证和推理的。
network_architecture.pdf（仅当安装了hiddenlayer时！）：包含网络架构图的pdf文档。
Progress.png：显示训练过程中的损失、伪骰子、学习率和纪元时间。顶部是训练期间的训练（蓝色）和验证（红色）损失图。还显示骰子的近似值（绿色）及其移动平均值（绿色虚线）。该近似值是前台类的平均 Dice 分数。我们需要对它持保留态度，因为它是根据每个 epoch 结束时的验证数据随机抽取的补丁来计算的，并且 Dice 计算的 TP、FP 和 FN 的聚合将补丁视为如果它们都源自同一卷（“全局 Dice”；我们不会为每个验证案例计算 Dice，然后对所有案例进行平均，而是假设只有一个验证案例可供我们采样补丁）。原因是“全局 Dice”在训练期间很容易计算，并且对于评估模型是否正在训练仍然非常有用。每个时期进行正确的验证需要很长时间才能完成。它在训练结束时运行。
validation_raw：此文件夹中是训练完成后预测的验证案例。此处的summary.json 文件包含验证指标（文件开头提供了所有情况的平均值）。
                如果--npz设置了，则压缩的 softmax 输出（另存为 .npz 文件）也位于此处。NPZ 文件是一种存储 NumPy 数组数据的文件格式，它是 NumPy 的一种压缩存储方式。

nnUNetv2_train 521 3d_lowres 0
nnUNetv2_train 521 3d_cascade_fullres 0
```
`UNET_CONFIGURATION `是一个字符串，用于标识所请求的 U-Net `配置/结构`（默认值：2d、3d_fullres、3d_lowres、3d_cascade_lowres）。
`DATASET_NAME_OR_ID `指定应训练哪个数据集，
`FOLD` 指定训练 5 折交叉验证的哪一倍。如果您想要训练特定的一折，您需要将 FOLD 替换为具体的折数，例如 0、1、2、3 或 4。 
如果您想要训练所有折数，您可以使用 "all" 作为参数。

####  nnU-Net 每 50 个 epoch 存储一个检查点。 如果需要继续之前的训练，只需`--c`在训练命令中添加 即可。
```angular2html
nnUNetv2_train 11 2d 4 --c
```

#### 3.2 重要提示：如果您`打算使用nnUNetv2_find_best_configuration`（见下文），请添加该`--npz`标志。
这使得 nnU-Net 在最终验证期间保存 softmax 输出。 为此需要他们。导出的 softmax 预测非常大，因此会占用大量磁盘空间，这就是默认情况下不启用此功能的原因。
## 如果您最初运行时没有该--npz标志，但现在需要 softmax 预测，只需使用以下命令重新运行`验证`：
`nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD --val --npz`
```angular2html
nnUNetv2_train 521 3d_fullres 0 --val --npz  
nnUNetv2_train 521 3d_fullres 1 --val --npz  
nnUNetv2_train 521 3d_fullres 2 --val --npz  
nnUNetv2_train 521 3d_fullres 3 --val --npz  
nnUNetv2_train 521 3d_fullres 4 --val --npz
      #添加验证标志，利于nnUNetv2_find_best_configuration使用，在最终验证期间保存 softmax 输出。
        如果--npz设置了，则压缩的 softmax 输出（另存为 .npz 文件）也位于此处。不设置就没有。
      结果在[training_log_2024_3_13_12_55_40.txt]在最新的训练日志中可以看到。

## 例如：[training_log_2024_3_13_12_55_40.txt]在最新的训练日志中可以看到：
2024-03-13 12:55:41.726604: The split file contains 5 splits.
2024-03-13 12:55:41.726604: Desired fold for training: 2
2024-03-13 12:56:40.013264: Validation complete
2024-03-13 12:56:40.014315: Mean Validation Dice:  0.3263134973137479
```
您可以使用 指定` nnU-net `应使用的设备`-device DEVICE`。 DEVICE 只能是 `cpu、cuda 或 mps`。如果您有多个 GPU，
请选择使用的 `GPU id CUDA_VISIBLE_DEVICES=X nnUNetv2_train [...]`（要求设备为 cuda）。
请参阅`nnUNetv2_train -h`参考资料 附加选项。`-device GPU:0,1`不行。
```
CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 11 2d 0 [--npz]
CUDA_VISIBLE_DEVICES=0,1 nnUNetv2_train 11 3d_fullres all [--npz]
``` 

## U-net配置/结构使用代码
2D U-Net(2D U-net)
```
#For FOLD in [0, 1, 2, 3, 4], run:
nnUNetv2_train 11 2d 0 [--npz]
```
3D full resolution U-Net(3D全分辨率U-Net)
```
For FOLD in [0, 1, 2, 3, 4], run:
nnUNetv2_train DATASET_NAME_OR_ID 3d_fullres FOLD [--npz]
```

## 3D U-Net cascade (3D U-Net 级联)

3D low resolution U-Net(3D低分辨率U-Net)
```
For FOLD in [0, 1, 2, 3, 4], run:
nnUNetv2_train DATASET_NAME_OR_ID 3d_lowres FOLD [--npz]
```
3D full resolution U-Net(3D全分辨率U-Net)
```
For FOLD in [0, 1, 2, 3, 4], run:
nnUNetv2_train DATASET_NAME_OR_ID 3d_cascade（层叠）_fullres FOLD [--npz]
```
## 注意，级联的3D全分辨率U-Net需要低分辨率U-Net的五倍才能完成！
训练后的模型将写入 `nnUNet_results`文件夹。每次训练都会获得一个自动生成的输出文件夹名称：
nnUNet_results/DatasetXXX_MYNAME/TRAINER_CLASS_NAME__PLANS_NAME__CONFIGURATION（配置）/FOLD
## 如nnUNet_results/Dataset011_Spleen/nnUNetTrainer__nnUNetPlans__2d/fold_0

例如，对于 Dataset002_Heart（来自 MSD），如下所示：
```
nnUNet_results/
├── Dataset002_Heart
    │── nnUNetTrainer__nnUNetPlans__2d
    │    ├── fold_0
    │    ├── fold_1
    │    ├── fold_2
    │    ├── fold_3
    │    ├── fold_4
    │    ├── dataset.json
    │    ├── dataset_fingerprint.json
    │    └── plans.json
    └── nnUNetTrainer__nnUNetPlans__3d_fullres
         ├── fold_0
         ├── fold_1
         ├── fold_2
         ├── fold_3
         ├── fold_4
         ├── dataset.json
         ├── dataset_fingerprint.json
         └── plans.json
```
请注意，这里不存在 3d_lowres 和 3d_cascade_fullres，因为该数据集没有触发级联。在每个模型训练输出文件夹（每个fold_x文件夹）中，将创建以下文件：
```angular2html
`debug.json`：包含用于训练该模型的蓝图和推断参数的摘要以及一堆其他内容。不容易阅读，但对于调试非常有用;-)
`checkpoint_best.pth`：训练期间识别的最佳模型的检查点文件。现在不使用，除非你明确告诉 nnU-Net 使用它。
`checkpoint_final.pth`：最终模型的检查点文件（训练结束后）。这是用于验证和推理的。
`network_architecture.pdf`（仅当安装了hiddenlayer时！）：包含网络架构图的pdf文档。
`Progress.png`：显示训练过程中的损失、伪骰子、学习率和纪元时间。顶部是训练期间的训练（蓝色）和验证（红色）损失图。
             还显示骰子的近似值（绿色）及其移动平均值（绿色虚线）。该近似值是前台类的平均 Dice 分数。我们需要对它持保留态度，
             因为它是根据每个 epoch 结束时的验证数据随机抽取的补丁来计算的，并且 Dice 计算的 TP、FP 和 FN 的聚合将补丁视为如
             果它们都源自同一卷（“全局 Dice”；我们不会为每个验证案例计算 Dice，然后对所有案例进行平均，而是假装只有一个验证案例
             可供我们采样补丁）。原因是“全局 Dice”在训练期间很容易计算，并且对于评估模型是否正在训练仍然非常有用。每个时期进行正
             确的验证需要很长时间才能完成。它在训练结束时运行。
`validation_raw`：此文件夹中是训练完成后预测的验证案例。此处的`summary.json` 文件包含验证指标（文件开头提供了所有情况的平均值）。
                如果`--npz`设置了，则压缩的 softmax 输出（另存为 .npz 文件）也位于此处。
```
在训练期间，观察进度通常很有用。因此，我们建议您在运行第一次训练时查看生成的`progress.png`。它将在每个纪元后更新。

训练时间很大程度上取决于 GPU。我们推荐用于训练的最小 GPU 是 Nvidia RTX 2080ti。这样，所有网络培训的时间都不超过 2 天。
请参阅我们的基准测试，看看您的系统是否按预期运行。


# 4.自动确定最佳配置（find_best_configuration）
## 一旦所需的配置经过训练（完全交叉验证），您就可以告诉 nnU-Net 自动识别最适合您的组合：
   nnUNetv2_find_best_configuration DATASET_NAME_OR_ID -c CONFIGURATIONS 
```angular2html
nnUNetv2_find_best_configuration 521 -c 3d_fullres
nnUNetv2_find_best_configuration 521 -c 2d 3d_fullres ...
如：
nnUNetv2_find_best_configuration 521 -c 3d_fullres
#这个命令会自动运行交叉验证，比较 2d 和 3d_fullres 配置的性能，并输出最佳配置的详细信息。

生成文件：
[crossval_results_folds_0_1_2_3_4]包括：
postprocessing.json后处理要用
postprocessing.pkl
summary.json
```
`CONFIGURATIONS`以下是您想要探索的配置列表。`默认情况下，`集成ensamble`是启用的`，这意味着 nnU-Net 将生成所有可能的`集成组合`
（每个集成有 `2`个配置）。这需要`包含验证集val预测概率`的 .npz 文件（与标志nnUNetv2_train一起 使用--npz，见上文）。
您可以通过设置标志来`禁用集成`:
```--disable_ensembling。```
请参阅`nnUNetv2_find_best_configuration -h`参考资料 了解更多选项。

`nnUNetv2_find_best_configuration` 还将自动确定应使用的后处理。nnU-Net 中的后处理仅考虑`去除`预测中`除最大分量之外的`所有分量.
（一次针对前景与背景，一次针对每个标签/区域）。

===============训练结束，开始测试（预测），生成预测图像（imagesTs）的标签，到这一步生成了[crossval_results_folds_0_1_2_3_4]交叉验证的最佳结果
===============只要模型训练出来后，有[crossval_results_folds_0_1_2_3_4]文件，我们就可以用从来没见过的[imagesTs]图像la_001_0000.nii.gz格式符合，就可以预测来分割，就是我们说的预推理！！！
===============模型保存在相应的训练折中fold 0、1、2、3、4，pkl文件保存了机器学习模型、数据预处理管道。
===============推理要有：[postprocessed_predictions]、[predictions]之外的所有文件
===============（预推理模型）推理后加文件：直接在[imagesTs]添加你要推理的图像（格式符合），即可推理！，不用修改json，直接运行相同指令，（默认推理5次，5个折叠）

### 完成后，该命令将准确地将您需要运行的命令打印到您的控制台来进行预测。它还会在`nnUNet_results/DATASET_NAME`文件夹中创建两个文件供您检查：
## `inference_instructions.txt`:再次包含您需要用于预测的确切命令！！！
`inference_information.json`:可以检查以查看所有配置和整体的性能，以及后处理的效果以及一些调试信息。
```angular2html  基本格式  删除除最大前景区域之外的所有区域 : 交叉验证的【postprocessed】后处理文件中（交叉验证后处理）： postprocessed/[summary.json]
***All results:*** 所有结果
nnUNetTrainer__nnUNetPlans__3d_fullres: 0.3035513523006785   # 结果

*Best*: nnUNetTrainer__nnUNetPlans__3d_fullres: 0.3035513523006785  #最好的

***Determining postprocessing for best model/ensemble***  确定最佳模型/集成的后处理 
Results were improved by removing all but the largest foreground region. Mean dice before: 0.30355 after: 0.36682
通过删除除最大前景区域之外的所有区域，结果得到了改善。平均骰子前：0.30355 后：0.36682  # 保存在"..\crossval_results_folds_0_1_2_3_4\postprocessed"交叉验证的【postprocessed】后处理文件中（交叉验证后处理）

***Run inference like this:*** 像这样运行推理（示例：-i INPUT_FOLDER输入数据所在的文件夹路径 -o OUTPUT_FOLDER希望保存推理结果的文件夹路径 ）

nnUNetv2_predict -d Dataset521_Heart -i INPUT_FOLDER -o OUTPUT_FOLDER -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetPlans

***Once inference is completed, run postprocessing like this:*** 推理完成后，像这样运行后处理

nnUNetv2_apply_postprocessing -i OUTPUT_FOLDER -o OUTPUT_FOLDER_PP -pp_pkl_file D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\postprocessing.pkl -np 8 -plans_json D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\plans.json```
```
```angular2html  解释推理指令 inference_instructions.txt
nnUNetv2_predict -d Dataset521_Heart -i INPUT_FOLDER -o OUTPUT_FOLDER -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetPlans
这里：
-d Dataset011_Spleen 指定了数据集ID或名称。
-i INPUT_FOLDER 是您的输入数据所在的文件夹路径。
-o OUTPUT_FOLDER 是您希望保存推理结果的文件夹路径。
-f 0 1 2 3 4 指定了使用哪些折叠进行推理。
-tr nnUNetTrainer 指定了训练器。
-c 2d 指定了配置，这里是2D。
-p nnUNetPlans 指定了计划文件。这是nnUNet用于确定网络配置和预处理步骤的文件。

2. 运行后处理
一旦推理完成，您可以使用nnUNetv2_apply_postprocessing命令来应用后处理，以进一步改善结果。
您需要替换OUTPUT_FOLDER和OUTPUT_FOLDER_PP为您自己的输出目录路径和希望保存后处理结果的目录路径。例如：
nnUNetv2_apply_postprocessing -i /path/to/your/output_folder -o /path/to/your/output_folder_pp -pp_pkl_file /path/to/miniconda3/lib/python3.8/site-packages/nnunetv2/nnUNet_results/Dataset011_Spleen/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/postprocessing.pkl -np 8 -plans_json /path/to/miniconda3/lib/python3.8/site-packages/nnunetv2/nnUNet_results/Dataset011_Spleen/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/plans.json

-i OUTPUT_FOLDER 是您的推理结果所在的文件夹路径。
-o OUTPUT_FOLDER_PP 是您希望保存后处理结果的文件夹路径。
-pp_pkl_file 指定了后处理配置文件的路径。
-np 8 指定了使用的处理器数量。
-plans_json 指定了计划文件的路径。
```
==========================推理前，先查看推理指令，最后生成[predictions]（创建）、和[postprocessed_predictions]文件（创建）
# 5.运行推理
请记住，位于输入文件夹中的数据必须具有与训练模型的数据集相同的文件结尾，并且必须遵守图像文件的 nnU-Net 命名方案（请参阅`数据集格式`和 `推理数据格式！`）
用于推理的数据格式必须与原始数据所使用的格式相匹配（具体来说，图像的格式必须与 imagesTr 文件夹中的格式完全相同）。
和以前一样，文件名必须以唯一标识符开头，后跟 4 位模态标识符。这是两个不同数据集的示例：
#### 用于推理的数据格式
任务005_前列腺：
此任务有 2 种模式，因此输入文件夹中的文件必须如下所示：
 input_folder
 ├── prostate_03_0000.nii.gz
 ├── prostate_03_0001.nii.gz
 ├── prostate_05_0000.nii.gz
 ├── prostate_05_0001.nii.gz
 ├── prostate_08_0000.nii.gz
 ├── prostate_08_0001.nii.gz
 ├── ...
_0000 必须是 T2 图像，_0001 必须是 ADC 图像（由 dataset.json 中的“channel_names”指定），与训练中使用的完全相同。

任务002_心脏：
 imagesTs
 ├── la_001_0000.nii.gz
 ├── la_002_0000.nii.gz
 ├── la_006_0000.nii.gz
 ├── ...
Task002 只有一种模态，因此每种情况只有一个 _0000.nii.gz 文件。
### 输出文件夹中的分段将命名为 {CASE_IDENTIFIER}.nii.gz（省略模态标识符）。
请记住，用于推理的文件格式（本例中为 .nii.gz）必须与用于训练的文件格式相同（并且与 dataset.json 中的“file_ending”中指定的文件格式相同）！

`nnUNetv2_find_best_configuration`（见上文）将使用您需要使用的推理命令将字符串打印到终端。运行推理的最简单方法就是使用这些命令。
如果您希望手动指定用于推理的configuration(配置)，请使用以下命令：

# 5.1.1运行预测（测试集 imagesTs）
对于每个所需的配置，运行
!!!仅当您打算使用`集成`时才指定` --save_probabilities`。
`--save_probabilities `将使命令`将预测概率与需要大量磁盘空间的预测分段掩码`一起保存。
```angular2html nnUNetv2_predict预测 Dataset521_Heart指定任务 更改：-i /path/to/imagesTs测试图像 -o /path/to/predictions 每个输入图像对应的预测分割图像  -f 0 1 2 3 4训练模型折数 -c 3d_fullres配置
nnUNetv2_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -d 11 -c CONFIGURATION --save_probabilities

例如，如果你的数据集ID是11，使用的配置是2d，命令可能如下所示：
nnUNetv2_predict -i /path/to/input_images -o /path/to/predictions -d 11 -c 2d --save_probabilities
命令执行完成后，检查输出文件夹（/path/to/predictions），你应该会看到每个输入图像对应的预测分割图像。

示例:
nnUNetv2_predict -d Dataset011_Spleen -i .../imagesTs -o .../(创建)predictions -f 0 1 2 3 4 -tr nnUNetTrainer -c 2d -p nnUNetPlans （格式）

（炼丹炉）:
nnUNetv2_predict -d Dataset011_Spleen -i miniconda3/lib/python3.8/site-packages/nnunetv2/nnUNet_raw/Dataset011_Spleen/imagesTs -o miniconda3/lib/python3.8/site-packages/nnunetv2/nnUNet_results/Dataset011_Spleen/nnUNetTrainer__nnUNetPlans__2d/predictions -f 0 1 2 3 4 -tr nnUNetTrainer -c 2d -p nnUNetPlans

1.用测试集进行测试(预测)，保存结果到【prediction】（创建），3d_fullres -p nnUNetPlans（要求单独文件）：
（本机指令运行）：
nnUNetv2_predict -d Dataset521_Heart -i D:\zhuomian\nnUNet_desk_v2\nnUNet_raw\Dataset521_Heart\imagesTs -o D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\predictions -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetPlans

生成文件[predict_from_raw_data_args.json]和"Dataset521_Heart的3d_fullres模型"预测的图像标签（来自imagesTs）

2.使用`集成`， '--save_probabilities' ：
（本机）nnUNetv2_predict -d Dataset521_Heart -i D:\zhuomian\nnUNet_desk_v2\nnUNet_raw\Dataset521_Heart\imagesTs -o D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\predictions -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetPlans  --save_probabilities
```
### `OUTPUT_FOLDER`请为每种配置（2d、3dfullers、...）选择`单独的！`
# 生成文件[predict_from_raw_data_args.json]和"Dataset521_Heart的3d_fullres模型"`所有 5 个折叠`作为一个`整体`预测的图像标签（来自imagesTs）

请注意，`默认`情况下，`推理`将通过交叉验证的`所有 5 个折叠`作为一个`整体`来完成。我们强烈建议您使用全部 5 折[0, 1, 2, 3, 4]。
因此，在`运行推理之前` 必须训练所有 5 个折叠。

如果您希望使用`单个模型`进行预测，请训练`all`折叠并将其指定`nnUNetv2_predict` 为`-f all`

# 5.1.2 集成多种配置(ensemble multiple configurations)
nnUNetv2_ensemble命令用于`将多个模型的预测结果进行集成（融合）`,5.1.1的多个预测的融合模型，以期望得到更好的预测性能。
如果您希望集成`多个预测`（通常形成`不同的配置`），可以使用以下命令来实现：
1首先，确保你已经有了多个不同模型的预测结果，这些结果应该是使用5.1的`nnUNetv2_predict`命令生成的，且保存在不同的文件夹中。
2例如，你可能有两个模型的预测结果分别保存在`/path/to/predictions1`和`/path/to/predictions2`文件夹中。
3选择一个文件夹用于保存集成后的预测结果，或者创建一个新的文件夹。确保这个文件夹是空的或者你不介意在其中写入新的文件。例如，你可以创建一个名为`/path/to/ensemble_predictions`的文件夹。
4运行集成命令：在命令行中运行`nnUNetv2_ensemble`命令，指定所有包含预测结果的文件夹、输出文件夹以及并行处理的进程数。

```angular2html 将多个模型的预测结果进行集成（融合） /predictions1  /predictions2 /ensemble_predictions(例如：创建3个文件夹），要求必须有.npz文件（）
nnUNetv2_ensemble -i FOLDER1 FOLDER2 ... -o OUTPUT_FOLDER -np NUM_PROCESSES
例如：
nnUNetv2_ensemble -i /path/to/predictions1 /path/to/predictions2 -o /path/to/ensemble_predictions -np 4
```
检查集成结果：命令执行完成后，检查输出文件夹（/path/to/ensemble_predictions），你应该会看到集成后的预测结果。
您可以指定任意数量的文件夹，但请记住，每个文件夹都需要包含由`nnUNetv2_predict.`生成的`npz`文件。
同样，`nnUNetv2_ensemble-h`将告诉您有关其他选项的更多信息。

# 5.2 应用后处理
最后，将先前确定的`后处理`应用于（集成ensembled）预测：
`nnUNetv2_apply_postprocessing`命令用于对nnUNetv2模型的预测结果应用后处理步骤，以改进预测的质量。
例如，如果你的后处理配置文件名为`postprocessing.pkl`，计划文件名为`plans.pkl`，数据集的JSON文件名为`dataset.json`，命令可能如下所示：
```angular2html 四个文件，见格式。【../predictions】预测文件（已创建） 【-o ../postprocessed_predictions】后处理预测文件pp（创建） 【-pp_pkl_file ../postprocessing.pkl】后处理的pkl文件（指令中已有） 【-plans_json ../crossval_results_folds_0_1_2_3_4/plans.json】交叉验证的plan.json文件（指令中已有）
nnUNetv2_apply_postprocessing -i FOLDER_WITH_PREDICTIONS -o OUTPUT_FOLDER --pp_pkl_file POSTPROCESSING_FILE -plans_json PLANS_FILE -dataset_json DATASET_JSON_FILE
nnUNetv2_apply_postprocessing -i ../predictions -o ../postprocessed_predictions --pp_pkl_file ../postprocessing.pkl -plans_json ../plans.pkl -dataset_json ../dataset.json
格式：nnUNetv2_apply_postprocessing -i  【../predictions】 【-o ../postprocessed_predictions】 【-pp_pkl_file ../postprocessing.pkl】 -np 8 【-plans_json ../crossval_results_folds_0_1_2_3_4/plans.json】

示例：
（炼丹炉）nnUNetv2_apply_postprocessing -i  miniconda3/lib/python3.8/site-packages/nnunetv2/nnUNet_results/Dataset011_Spleen/nnUNetTrainer__nnUNetPlans__2d/predictions -o miniconda3/lib/python3.8/site-packages/nnunetv2/nnUNet_results/Dataset011_Spleen/nnUNetTrainer__nnUNetPlans__2d/postprocessed_predictions -pp_pkl_file miniconda3/lib/python3.8/site-packages/nnunetv2/nnUNet_results/Dataset011_Spleen/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/postprocessing.pkl -np 8 -plans_json miniconda3/lib/python3.8/site-packages/nnunetv2/nnUNet_results/Dataset011_Spleen/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/plans.json

（推理指令）nnUNetv2_apply_postprocessing -i OUTPUT_FOLDER -o OUTPUT_FOLDER_PP -pp_pkl_file D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\postprocessing.pkl -np 8 -plans_json D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\plans.json```
运行指令（推理其他同样）：
nnUNetv2_apply_postprocessing -i D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\predictions -o D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\postprocessed_predictions -pp_pkl_file D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\postprocessing.pkl -np 8 -plans_json D:\zhuomian\nnUNet_desk_v2\nnUNet_results\Dataset521_Heart\nnUNetTrainer__nnUNetPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\plans.json

因为有文件绝对路径，所以非常长！！！
-i OUTPUT_FOLDER 是您的推理结果所在的文件夹路径。
-o OUTPUT_FOLDER_PP 是您希望保存后处理结果的文件夹路径。
-pp_pkl_file 指定了后处理配置文件的路径。
-np 8 指定了使用的处理器数量。
-plans_json 指定了计划文件的路径。

生成结果：[postprocessed_predictions]输出后处理的预测分割图像。
```
# 生成结果：[postprocessed_predictions]输出[后处理]的"Dataset521_Heart的3d_fullres模型"`所有 5 个折叠`作为一个`整体`预测的图像标签（来自imagesTs）。

`nnUNetv2_find_best_configuration`（或其生成的`inference_instructions.txt`文件）将告诉您在哪里可以找到`后处理文件`。
如果没有，您可以在`result`文件夹中查找它（它被创造性地命名为`postprocessing.pkl`）。
如果您的源文件夹来自`集成ensemble`，您还需要指定一个`-plans_json`文件和一个`-dataset_json`应使用的文件（对于单个配置预测，
这些文件会自动从相应的训练中复制）。您可以从任何 ensemble members 中挑选这些文件。


# 5.4如何使用预训练模型进行推理
重要提示：nnU-Net v1 的预训练权重与 V2 不兼容。您将需要使用新版本重新培训。
但老实说，您已经拥有一个经过充分训练的模型，可以使用它来运行推理（在 v1 中），所以只需继续使用它即可！
尚不适用于 V2 :-( 如果您希望使用预训练模型进行推理，请立即查看旧的 nnU-Net。我们正在全力以赴！

完成它！
v1运行推理

-----------------------------------------------------------------------------------------------------------------------

要编辑系统的环境变量，可以按照以下步骤在Windows操作系统中进行：

[//]: # (打开系统属性：.)
在Windows 10中，右键单击“此电脑”或“计算机”图标，然后选择“属性”。
在Windows 7中，右键单击“计算机”，然后选择“属性”。
打开高级系统设置：
在左侧面板中，选择“高级系统设置”。
打开环境变量：
在弹出的窗口中，点击“环境变量”按钮。
编辑系统环境变量：
在“系统变量”部分，可以添加、编辑或删除系统的环境变量。点击“新建”来添加一个新的环境变量，点击“编辑”来修改一个已有的环境变量，点击“删除”来删除一个环境变量。
保存更改：
在完成所有修改后，点击“确定”来保存更改。
```
C:\Users\13639>echo %nnUNet_raw%
```
D:\nnunetv2\nnUNet\DATASET\nnUNet_raw

------------------------------------------------------------------------------------------------
# 不能选择的的id
![img.png](../../img.png)

数据集文件夹结构
数据集必须位于该`nnUNet_raw`文件夹中（您可以在安装 nnU-Net 时定义该文件夹，也可以在每次打算运行 nnU-Net 命令时导出/设置！）。
每个分割数据集都存储为单独的“数据集”。
数据集与数据集 ID、三位数整数和数据集名称（您可以自由选择）相关联：
例如，Dataset005_Prostate 的数据集名称为“Prostate”，数据集 id 为 5。数据集存储在如下文件夹`nnUNet_raw`中这：
```
nnUNet_raw/
├── Dataset001_BrainTumour
├── Dataset002_Heart
├── Dataset003_Liver
├── Dataset004_Hippocampus
├── Dataset005_Prostate
├── ...
在每个数据集文件夹中，预计具有以下结构：

Dataset001_BrainTumour/
├── dataset.json
├── imagesTr      # imagesTr包含属于训练案例的图像
├── imagesTs       # optional（可选）包含属于测试用例的图像。
└── labelsTr        #包含带有训练案例的領域实况分割图的图像。
```
添加自定义数据集时，请查看`dataset_conversion`文件夹并选择`尚未使用的 ID`。`ID 001-010`用于医疗细分十项全能。

imagesTr包含属于训练案例的图像。nnU-Net 将执行管道配置、交叉验证训练，以及使用这些数据寻找后处理和最佳集成。
imagesTs（可选）包含属于测试用例的图像。nnU-Net 不使用它们！这可能只是您存储这些图像的一个方便的位置。Medical Segmentation Decathlon 文件夹结构的残余。
labelsTr包含带有训练案例的地面实况分割图的图像。
dataset.json包含数据集的元数据。

### 上面介绍的方案产生以下文件夹结构。给出了 `MSD `第一个数据集的示例：
BrainTumour。该数据集有四个输入通道：FLAIR (0000)、T1w (0001)、T1gd (0002) 和 T2w (0003)。
请注意，imageTs 文件夹是可选的，并且不必存在。
```nnUNet_raw（文件夾）/Dataset001_BrainTumour（文件夾）/
├── dataset.json
├── imagesTr （訓練集）
│   ├── BRATS_001_0000.nii.gz    #  (名称_id_通道id_格式）
│   ├── BRATS_001_0001.nii.gz
│   ├── BRATS_001_0002.nii.gz
│   ├── BRATS_001_0003.nii.gz
│   ├── BRATS_002_0000.nii.gz
│   ├── BRATS_002_0001.nii.gz
│   ├── BRATS_002_0002.nii.gz
│   ├── BRATS_002_0003.nii.gz
│   ├── ...
├── imagesTs
│   ├── BRATS_485_0000.nii.gz
│   ├── BRATS_485_0001.nii.gz
│   ├── BRATS_485_0002.nii.gz
│   ├── BRATS_485_0003.nii.gz
│   ├── BRATS_486_0000.nii.gz
│   ├── BRATS_486_0001.nii.gz
│   ├── BRATS_486_0002.nii.gz
│   ├── BRATS_486_0003.nii.gz
│   ├── ...
└── labelsTr
    ├── BRATS_001.nii.gz
    ├── BRATS_002.nii.gz
    ├── ...
```
----------------------------------------------------------------

nnU-Net 依靠`环境变量`来了解原始数据、预处理数据和训练模型权重的存储位置。要使用 nnU-Net 的完整功能，必须设置以下三个环境变量：
`nnUNet_raw`：这是放置原始数据集的位置。此文件夹将`为每个数据集名称 DatasetXXX_YYY 提供一个子文件夹`，
其中 XXX 是 3 位标识符（例如 001、002、043、999...），YYY 是（唯一）数据集名称。数据集必须采用 nnU-Net 格式，请参阅此处。
```
`树结构示例：`
nnUNet_raw / `Dataset001_NAME1`(数据集001_名称)
├── `dataset.json`（定义通道、标签、读者、训练）
├── `imagesTr`（必须）
│   ├── ...
├── imagesTs
│   ├── ...
└── `labelsTr`（必须一样）
    ├── ...
nnUNet_raw/ `Dataset002_NAME2`（数据集002_名称）
├── dataset.json
├── imagesTr
│   ├── ...
├── imagesTs
│   ├── ...
└── labelsTr
    ├── ...
```
nnUNet_preprocessed：这是保存预处理数据的文件夹。训练期间还将从此文件夹中读取数据。重要的是，该文件夹位于具有低访问延迟和高吞吐量的驱动器上（例如 nvme SSD（PCIe gen 3 就足够了））。

nnUNet_results：指定 nnU-Net 保存模型权重的位置。如果下载了预训练模型，则会将其保存在此处。

------------------------


### 该数据集有四个输入通道：FLAIR (0000)、T1w (0001)、T1gd (0002) 和 T2w (0003)。请注意，imageTs 文件夹是可选的，并且不必存在。
```
nnUNet_raw/Dataset001_BrainTumour/
├── dataset.json
├── imagesTr（必须）
│   ├── BRATS_001_0000.nii.gz  #BRATS（Brain Tumor Segmentation Challenge缩写)_001(数据集001)_0000(通道名称).nii.gz格式
│   ├── BRATS_001_0001.nii.gz    #  (名称_id_通道id_格式）
│   ├── BRATS_001_0002.nii.gz
│   ├── BRATS_001_0003.nii.gz
│   ├── BRATS_002_0000.nii.gz
│   ├── BRATS_002_0001.nii.gz
│   ├── BRATS_002_0002.nii.gz
│   ├── BRATS_002_0003.nii.gz
│   ├── ...
├── imagesTs(可选)
│   ├── BRATS_485_0000.nii.gz
│   ├── BRATS_485_0001.nii.gz
│   ├── BRATS_485_0002.nii.gz
│   ├── BRATS_485_0003.nii.gz
│   ├── BRATS_486_0000.nii.gz
│   ├── BRATS_486_0001.nii.gz
│   ├── BRATS_486_0002.nii.gz
│   ├── BRATS_486_0003.nii.gz
│   ├── ...
└── labelsTr（必须）
    ├── BRATS_001.nii.gz  #（大脑肿瘤分割挑战赛_数据集001.nii.gz格式）
    ├── BRATS_002.nii.gz   #  (名称_id_格式），标签在json问文件中定义
    ├── ...
```
#### 这是 MSD 第二个数据集的另一个示例，它只有一个输入通道：

```nnUNet_raw/Dataset002_Heart 
#### 格式：(DatasetXXX_YYY=Dataset002_心脏 =Dataset（3位）标识符_（唯一）数据集名称)/
├── dataset.json
├── imagesTr（必须）
│   ├── la_003_0000.nii.gz
│   ├── la_004_0000.nii.gz
│   ├── ...
├── imagesTs（可选）
│   ├── la_001_0000.nii.gz
│   ├── la_002_0000.nii.gz
│   ├── ...
└── labelsTr（必须）
    ├── la_003.nii.gz
    ├── la_004.nii.gz
    ├── ...
```

#### dataset.json 包含 nnU-Net 训练所需的元数据。

##### 以下是 MSD 的 Dataset005_Prostate 示例中的 dataset.json 的样子：
```{ 
 "channel_names": {  # formerly modalities（原模式）
   "0": "T2", #（定义通道名称）（0为T2）
   "1": "ADC" #(1为AUC)
 }, 
 "labels": {  # THIS IS DIFFERENT NOW!（不同）# 标签的结构不同,（name -> int 而不是 int -> name）。这是支持基于区域的培训所必需的!!!
   "background": 0, #（定义标签）（"背景":0）  
   "PZ": 1,  #（前列腺外周区域（Peripheral Zone）为1）  
   "TZ": 2   #（前列腺过渡区域（Transition Zone）为2）
 }, 
 "numTraining": 32,   #"numTraining" 是一个参数或变量，这个值表示`训练集中样本的数量`。
 "file_ending": ".nii.gz"  #"file_ending" 通常用于指代文件的后缀或文件扩展名。添加“file_ending”以支持不同的输入文件类型.
 "overwrite_image_reader_writer": "SimpleITKIO"  # 可选!如果没有提供，nnU-Net将自动确定ReaderWriter
 }
```
---------------------

默认情况下，支持以下文件格式：
## overwrite_image_reader_writer: 如果你的数据集需要一个特殊的 IO 类，你可以从BaseReaderWriter 派生它，将其放入 nnunet.imageio 并在这里通过名称引用它
NaturalImage2DIO：`.png`、`.bmp`、`.tif`
NibabelIO：`.nii.gz`、`.nrrd`、`.mha`
NibabelIOWithReorient：`.nii.gz`、`.nrrd`、`.mha`。该阅读器会将图像重新定向为 RAS！Remote Access Server (远程访问服务器)：
SimpleITKIO：`.nii.gz`、`.nrrd`、`.mha`
Tiff3DIO：`.tif、.tiff.3D tif `图像！由于 TIF 没有存储间距信息的标准化方法，因此 nnU-Net 期望每个 TIF 文件都附带一个包含此信息的同名 .json 文件（请参阅 此处）。


### 如上所述，TIFF 文件需要包含间距信息的 `json `文件。
单位对应于`x 和 y 中的 7.6`、
`z 中的 80 `的 
`3D TIFF `堆栈示例如下：
```
{
    "spacing": [7.6, 7.6, 80.0]
}
```
在数据集文件夹中，此文件（`cell6.json`在本示例中命名）将放置在以下文件夹中：
```
nnUNet_raw/Dataset123_Foo/
├── dataset.json
├── imagesTr
│   ├── cell6.json       #包含间距信息的 `json `文件
│   └── cell6_0000.tif   #TIFF 文件.  名称id_通道id.文件格式
└── labelsTr
    ├── cell6.json
    └── cell6.tif
```
